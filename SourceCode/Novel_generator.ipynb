{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "copy_Novel generator",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXOTyoXbZKNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmCAwR5rZMrg",
        "colab_type": "text"
      },
      "source": [
        "Text Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LROGUH6xZRQP",
        "colab_type": "code",
        "outputId": "18bd45cd-78c0-44a4-f8f7-9546d89f62e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyUyeneJd_m3",
        "colab_type": "code",
        "outputId": "b52f2934-c005-4856-d7ce-27a73b417f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Code to read file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1w4lOacBmOtly-ozf8Ncfrl4oCL4minZ8'\n",
        "\n",
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "raw_text = downloaded.GetContentString()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1w4lOacBmOtly-ozf8Ncfrl4oCL4minZ8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q1Wl5k8riUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ6PuI7nWCai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(raw_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUfBcAsIXQjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxsyOwYWXay5",
        "colab_type": "code",
        "outputId": "dbf4dc8c-01f8-4efe-f511-bbf556c64868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  94275\n",
            "Total Vocab:  38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "has4F79NXwUz",
        "colab_type": "code",
        "outputId": "a6edd672-a799-49f9-9e77-289ef8ca0a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  94175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeSkBwa6BF5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perplexity(y_true, y_pred):\n",
        "    \n",
        "    cross_entropy = K.categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = K.exp(cross_entropy)\n",
        "    return perplexity\n",
        "\n",
        "\n",
        "def crossentropy(y_true, y_pred):\n",
        "    return K.categorical_crossentropy(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abxpmQHyYIw1",
        "colab_type": "code",
        "outputId": "27683bed-be5c-4fb3-90a1-2c73c31757a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "\n",
        "y = np_utils.to_categorical(dataY)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(94175, 100, 1)\n",
            "(94175, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNAMlEpAjlUl",
        "colab_type": "code",
        "outputId": "d7d7f371-a6db-4492-818a-c6fba3b16340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(512))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[crossentropy, perplexity])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H8PykF60xhL",
        "colab_type": "code",
        "outputId": "b8354f7e-f4a8-4a93-cb7d-192776d469f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100, 512)          1052672   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 38)                19494     \n",
            "=================================================================\n",
            "Total params: 3,171,366\n",
            "Trainable params: 3,171,366\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJEb1uY8lEOf",
        "colab_type": "code",
        "outputId": "8929e839-c343-4c08-e500-caa333661844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit the model\n",
        "model.fit(X, y, epochs=50, batch_size=2000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "94175/94175 [==============================] - 70s 740us/step - loss: 3.0983 - crossentropy: 3.0983 - perplexity: 34.5722\n",
            "Epoch 2/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.9949 - crossentropy: 2.9949 - perplexity: 35.6375\n",
            "Epoch 3/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.9872 - crossentropy: 2.9872 - perplexity: 35.7610\n",
            "Epoch 4/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 2.9550 - crossentropy: 2.9550 - perplexity: 36.3816\n",
            "Epoch 5/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 2.8611 - crossentropy: 2.8611 - perplexity: 36.3038\n",
            "Epoch 6/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.7927 - crossentropy: 2.7927 - perplexity: 36.1388\n",
            "Epoch 7/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.7378 - crossentropy: 2.7378 - perplexity: 35.1580\n",
            "Epoch 8/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.6869 - crossentropy: 2.6869 - perplexity: 34.6630\n",
            "Epoch 9/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.6476 - crossentropy: 2.6476 - perplexity: 34.8739\n",
            "Epoch 10/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.6041 - crossentropy: 2.6041 - perplexity: 34.6344\n",
            "Epoch 11/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.5724 - crossentropy: 2.5724 - perplexity: 35.4256\n",
            "Epoch 12/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.5314 - crossentropy: 2.5314 - perplexity: 34.7219\n",
            "Epoch 13/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 2.4934 - crossentropy: 2.4934 - perplexity: 35.8877\n",
            "Epoch 14/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.4565 - crossentropy: 2.4565 - perplexity: 35.7120\n",
            "Epoch 15/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.4260 - crossentropy: 2.4260 - perplexity: 34.2490\n",
            "Epoch 16/50\n",
            "94175/94175 [==============================] - 62s 661us/step - loss: 2.3923 - crossentropy: 2.3923 - perplexity: 33.1740\n",
            "Epoch 17/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.3518 - crossentropy: 2.3518 - perplexity: 33.5851\n",
            "Epoch 18/50\n",
            "94175/94175 [==============================] - 62s 661us/step - loss: 2.3189 - crossentropy: 2.3189 - perplexity: 32.0569\n",
            "Epoch 19/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.2907 - crossentropy: 2.2907 - perplexity: 31.9088\n",
            "Epoch 20/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 2.2593 - crossentropy: 2.2593 - perplexity: 30.8166\n",
            "Epoch 21/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.2288 - crossentropy: 2.2288 - perplexity: 30.9526\n",
            "Epoch 22/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.2023 - crossentropy: 2.2023 - perplexity: 31.7994\n",
            "Epoch 23/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.1751 - crossentropy: 2.1751 - perplexity: 29.7813\n",
            "Epoch 24/50\n",
            "94175/94175 [==============================] - 62s 661us/step - loss: 2.1453 - crossentropy: 2.1453 - perplexity: 30.5344\n",
            "Epoch 25/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 2.1193 - crossentropy: 2.1193 - perplexity: 30.0397\n",
            "Epoch 26/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.0816 - crossentropy: 2.0816 - perplexity: 29.2598\n",
            "Epoch 27/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 2.0577 - crossentropy: 2.0577 - perplexity: 29.5176\n",
            "Epoch 28/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 2.0536 - crossentropy: 2.0536 - perplexity: 30.3949\n",
            "Epoch 29/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 2.0002 - crossentropy: 2.0002 - perplexity: 28.4749\n",
            "Epoch 30/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 1.9723 - crossentropy: 1.9723 - perplexity: 28.8235\n",
            "Epoch 31/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.9399 - crossentropy: 1.9399 - perplexity: 28.9055\n",
            "Epoch 32/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 1.9069 - crossentropy: 1.9069 - perplexity: 28.2422\n",
            "Epoch 33/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.8733 - crossentropy: 1.8733 - perplexity: 26.7320\n",
            "Epoch 34/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.8385 - crossentropy: 1.8385 - perplexity: 26.3317\n",
            "Epoch 35/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.7991 - crossentropy: 1.7991 - perplexity: 25.9809\n",
            "Epoch 36/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 1.7638 - crossentropy: 1.7638 - perplexity: 25.8084\n",
            "Epoch 37/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.7239 - crossentropy: 1.7239 - perplexity: 23.5762\n",
            "Epoch 38/50\n",
            "94175/94175 [==============================] - 62s 661us/step - loss: 1.6886 - crossentropy: 1.6886 - perplexity: 24.1285\n",
            "Epoch 39/50\n",
            "94175/94175 [==============================] - 63s 664us/step - loss: 1.6399 - crossentropy: 1.6399 - perplexity: 22.7892\n",
            "Epoch 40/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 1.6076 - crossentropy: 1.6076 - perplexity: 20.5372\n",
            "Epoch 41/50\n",
            "94175/94175 [==============================] - 62s 662us/step - loss: 1.5752 - crossentropy: 1.5752 - perplexity: 20.2026\n",
            "Epoch 42/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.5280 - crossentropy: 1.5280 - perplexity: 20.2930\n",
            "Epoch 43/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.4840 - crossentropy: 1.4840 - perplexity: 19.9869\n",
            "Epoch 44/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.4328 - crossentropy: 1.4328 - perplexity: 18.1012\n",
            "Epoch 45/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.3846 - crossentropy: 1.3846 - perplexity: 18.5780\n",
            "Epoch 46/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.3434 - crossentropy: 1.3434 - perplexity: 16.6680\n",
            "Epoch 47/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.3050 - crossentropy: 1.3050 - perplexity: 17.5970\n",
            "Epoch 48/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.2561 - crossentropy: 1.2561 - perplexity: 25.2333\n",
            "Epoch 49/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.2138 - crossentropy: 1.2138 - perplexity: 14.9892\n",
            "Epoch 50/50\n",
            "94175/94175 [==============================] - 62s 663us/step - loss: 1.1784 - crossentropy: 1.1784 - perplexity: 14.3583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81370cb128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dot4p39B8ENX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def sample(preds, temperature=1.0):\n",
        "#     # helper function to sample an index from a probability array\n",
        "#     preds = np.asarray(preds).astype('float64')\n",
        "#     preds = np.log(preds) / temperature\n",
        "#     exp_preds = np.exp(preds)\n",
        "#     preds = exp_preds / np.sum(exp_preds)\n",
        "#     probas = np.random.multinomial(1, preds, 1)\n",
        "#     return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faoCXlWKDtFY",
        "colab_type": "code",
        "outputId": "12be6146-7a18-4d73-8aa5-edb060b55fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "\n",
        "\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\"  state,\n",
            "and trouble deaf heaven with my bootless cries,\n",
            "and look upon my self and curse my fate,\n",
            "wis \"\n",
            "hin the love thee sit she surength of lays,\n",
            "so should the steasure of thy silf desengs,\n",
            "and that in thee that shou dost coom the shee,\n",
            "which sake to booptait of the ruimed shile,\n",
            "then that meke bea for me wou in my heart,\n",
            "and meke to thee to fave then my sooe spuessed,\n",
            "but thos art to see shale of your seroest,\n",
            "and that in thee this ioows that thou drst st,\n",
            "to fiat to make thes born that i worlds,\n",
            "which in the world s secked shake i am standed\n",
            "\n",
            "to me that live in thee i am forg toon.\n",
            "\n",
            "\n",
            "\n",
            "that thie of this allne tit doth reme so thee.\n",
            "\n",
            "\n",
            "\n",
            "mn the danl of this blund with this gave thee mort in maru so the wirl and sase  \n",
            "\n",
            "but thou the world will be thy love and stand,\n",
            "but thou the sime thes seal the strlng ouce,\n",
            "and to the part of lapu siat in my beees,\n",
            "and lekd my self to beauty sersed mone dace,\n",
            "and therefore layst are soeek of so the seare,\n",
            "and beauty shall beauty leke to me ae tomd.\n",
            "for that shou hast that i am not love thae in,\n",
            "\n",
            "\n",
            "\n",
            "to shou the ttmenet of wourh diserace to be,\n",
            "that i am \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JykP46T8z4zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dXnIoaKz2fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_q3PaoF7_zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}